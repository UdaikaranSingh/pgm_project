{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_ns = [200, 500, 1000, 10000, 50000]\n",
    "all_ps = [5, 10, 100, 200]\n",
    "\n",
    "select_ns = [200]\n",
    "select_ps = all_ps\n",
    "\n",
    "train_summaries_dfs = {}\n",
    "validation_summaries_dfs = {}\n",
    "for n in all_ns:\n",
    "    for p in select_ps:\n",
    "        \n",
    "#         if n not in select_ns or sd not in select_sds:\n",
    "#             continue\n",
    "            \n",
    "        train_filename = f'train_summary_p_{p}_n_{n}.csv'\n",
    "        train_df = pd.read_csv(train_filename, index_col=0)\n",
    "        train_df['n'] = n\n",
    "        train_df['sd'] = p\n",
    "\n",
    "        validation_filename = f'validation_summary_p_{p}_n_{n}.csv'\n",
    "        validation_df = pd.read_csv(validation_filename, index_col=0)\n",
    "        validation_df['n'] = n\n",
    "        validation_df['p'] = p\n",
    "        \n",
    "        train_summaries_dfs[f'n:{n}, p:{p}'] = train_df\n",
    "        validation_summaries_dfs[f'n:{n}, p:{p}'] = validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_summaries_df = pd.concat(train_summaries_dfs.values(), axis=0).reset_index()\n",
    "all_train_summaries_df.columns = ['model'] + list(all_train_summaries_df.columns[1:])\n",
    "all_validation_summaries_df = pd.concat(validation_summaries_dfs.values(), axis=0).reset_index()\n",
    "all_validation_summaries_df.columns = ['model'] + list(all_validation_summaries_df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_validation_summaries_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "all_ns = [200, 500, 1000, 10000, 50000]\n",
    "all_ps = [5, 10, 100, 200]\n",
    "\n",
    "select_ns = [200]\n",
    "select_ps = all_ps\n",
    "\n",
    "preds_pkls = {}\n",
    "for n in all_ns:\n",
    "    for p in all_ps:\n",
    "        \n",
    "#         if n not in select_ns or sd not in select_sds:\n",
    "#             continue\n",
    "            \n",
    "        filename = f'preds_dict_train_n_{n}_p_{p}.pkl'\n",
    "        with open(filename, 'rb') as handle:\n",
    "            preds_pkl = pickle.load(handle)\n",
    "            preds_pkls[f'n:{n}, p:{p}'] = preds_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.metrics import mean_squared_error as mse\n",
    "# from sklearn.metrics import auc\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# from causalml.inference.meta import (\n",
    "#     BaseXRegressor,\n",
    "#     BaseRRegressor,\n",
    "#     BaseSRegressor,\n",
    "#     BaseTRegressor,\n",
    "# )\n",
    "# from causalml.propensity import ElasticNetPropensityModel\n",
    "# from causalml.dataset import simulate_nuisance_and_easy_treatment\n",
    "\n",
    "# from MyRegressor import *\n",
    "import os\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "KEY_GENERATED_DATA = \"generated_data\"\n",
    "KEY_ACTUAL = \"Actuals\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "LOAD_DATA = False\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "\n",
    "def distr_plot_single_sim(\n",
    "    synthetic_preds,\n",
    "    savepath,\n",
    "    kind=\"kde\",\n",
    "    include_learners=[],\n",
    "    bins=50,\n",
    "    histtype=\"step\",\n",
    "    alpha=1,\n",
    "    linewidth=1,\n",
    "    bw_method=1,\n",
    "):\n",
    "    \"\"\"Plots the distribution of each learner's predictions (for a single simulation).\n",
    "    Kernel Density Estimation (kde) and actual histogram plots supported.\n",
    "    Args:\n",
    "        synthetic_preds (dict): dictionary of predictions generated by get_synthetic_preds()\n",
    "        kind (str, optional): 'kde' or 'hist'\n",
    "        drop_learners (list, optional): list of learners (str) to omit when plotting\n",
    "        bins (int, optional): number of bins to plot if kind set to 'hist'\n",
    "        histtype (str, optional): histogram type if kind set to 'hist'\n",
    "        alpha (float, optional): alpha (transparency) for plotting\n",
    "        linewidth (int, optional): line width for plotting\n",
    "        bw_method (float, optional): parameter for kde\n",
    "    \"\"\"\n",
    "    \n",
    "    learners = include_learners\n",
    "    preds_for_plot = {}\n",
    "    for l in learners:\n",
    "        preds_for_plot[l] = synthetic_preds[l]\n",
    "    \n",
    "    # deleted generated data and assign actual value\n",
    "    del preds_for_plot[KEY_GENERATED_DATA]\n",
    "    global_lower = np.percentile(np.hstack(preds_for_plot.values()), 1)\n",
    "    global_upper = np.percentile(np.hstack(preds_for_plot.values()), 99)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cmap = get_cmap(len(learners))\n",
    "    for i, (k, v) in enumerate(preds_for_plot.items()):\n",
    "        if k in learners:\n",
    "            if kind == \"kde\":\n",
    "                v = pd.Series(v.flatten())\n",
    "                v = v[v.between(global_lower, global_upper)]\n",
    "                v.plot(\n",
    "                    kind=\"kde\",\n",
    "                    bw_method=bw_method,\n",
    "                    label=k,\n",
    "                    linewidth=linewidth,\n",
    "                    color=cmap(i),\n",
    "                )\n",
    "            elif kind == \"hist\":\n",
    "                plt.hist(\n",
    "                    v,\n",
    "                    bins=np.linspace(global_lower, global_upper, bins),\n",
    "                    label=k,\n",
    "                    histtype=histtype,\n",
    "                    alpha=alpha,\n",
    "                    linewidth=linewidth,\n",
    "                    color=cmap(i),\n",
    "                )\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    plt.xlim(global_lower, global_upper)\n",
    "    #plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.legend()\n",
    "    plt.title(\"Distribution from a Single Simulation\")\n",
    "    plt.savefig(savepath)\n",
    "\n",
    "def plot_dist(dictionary, linear_models, save_path, alpha = 0.2, bins = 30):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    keys = dictionary.keys()\n",
    "    lin_models = linear_models\n",
    "    not_lin_models = [key for key in keys if key not in linear_models]\n",
    "    for k in not_lin_models:\n",
    "        values = dictionary[k]\n",
    "        plt.hist(values, alpha = alpha, bins = bins, label = k, range=[-0.5, 2])\n",
    "    for k in lin_models:\n",
    "        values = dictionary[k]\n",
    "        plt.axvline(values[0], label=k,\n",
    "           linestyle='dotted', color=np.random.rand(3,), linewidth=2)\n",
    "    plt.title('Distribution of CATE Predictions by Meta Learner')\n",
    "    plt.xlabel('Individual Treatment Effect (ITE/CATE)')\n",
    "    plt.ylabel('# of Samples')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "def scatter_plot_summary(synthetic_summary, savepath, k, drop_learners=[], drop_cols=[]):\n",
    "    \"\"\"Generates a scatter plot comparing learner performance. Each learner's performance is plotted as a point in the\n",
    "    (Abs % Error of ATE, MSE) space.\n",
    "    Args:\n",
    "        synthetic_summary (pd.DataFrame): summary generated by get_synthetic_summary()\n",
    "        k (int): number of simulations (used only for plot title text)\n",
    "        drop_learners (list, optional): list of learners (str) to omit when plotting\n",
    "        drop_cols (list, optional): list of metrics (str) to omit when plotting\n",
    "    \"\"\"\n",
    "    plot_data = synthetic_summary.drop(drop_learners).drop(drop_cols, axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(12, 8)\n",
    "    xs = plot_data[\"Abs % Error of ATE\"]\n",
    "    ys = plot_data[\"MSE\"]\n",
    "\n",
    "    ax.scatter(xs, ys)\n",
    "\n",
    "    ylim = ax.get_ylim()\n",
    "    xlim = ax.get_xlim()\n",
    "\n",
    "    for i, txt in enumerate(plot_data.index):\n",
    "        ax.annotate(\n",
    "            txt,\n",
    "            (\n",
    "                xs[i] - np.random.binomial(1, 0.5) * xlim[1] * 0.04,\n",
    "                ys[i] - ylim[1] * 0.03,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Abs % Error of ATE\")\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_title(\"Learner Performance (averaged over k={} simulations)\".format(k))\n",
    "    plt.savefig(savepath)\n",
    "\n",
    "def scatter_plot_summary_holdout(\n",
    "    train_summary,\n",
    "    validation_summary,\n",
    "    k,\n",
    "    savepath,\n",
    "    label=[\"Train\", \"Validation\"],\n",
    "    drop_learners=[],\n",
    "    drop_cols=[],\n",
    "):\n",
    "    \"\"\"Generates a scatter plot comparing learner performance by training and validation.\n",
    "    Args:\n",
    "        train_summary (pd.DataFrame): summary for training synthetic data generated by get_synthetic_summary_holdout()\n",
    "        validation_summary (pd.DataFrame): summary for validation synthetic data generated by\n",
    "            get_synthetic_summary_holdout()\n",
    "        label (string, optional): legend label for plot\n",
    "        k (int): number of simulations (used only for plot title text)\n",
    "        drop_learners (list, optional): list of learners (str) to omit when plotting\n",
    "        drop_cols (list, optional): list of metrics (str) to omit when plotting\n",
    "    \"\"\"\n",
    "    train_summary = train_summary.drop(drop_learners).drop(drop_cols, axis=1)\n",
    "    validation_summary = validation_summary.drop(drop_learners).drop(drop_cols, axis=1)\n",
    "\n",
    "    plot_data = pd.concat([train_summary, validation_summary])\n",
    "    plot_data[\"label\"] = [i.replace(\"Train\", \"\") for i in plot_data.index]\n",
    "    plot_data[\"label\"] = [i.replace(\"Validation\", \"\") for i in plot_data.label]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(12, 8)\n",
    "    xs = plot_data[\"Abs % Error of ATE\"]\n",
    "    ys = plot_data[\"MSE\"]\n",
    "    group = np.array(\n",
    "        [label[0]] * train_summary.shape[0] + [label[1]] * validation_summary.shape[0]\n",
    "    )\n",
    "    cdict = {label[0]: \"red\", label[1]: \"blue\"}\n",
    "\n",
    "    for g in np.unique(group):\n",
    "        ix = np.where(group == g)[0].tolist()\n",
    "        ax.scatter(xs[ix], ys[ix], c=cdict[g], label=g, s=100)\n",
    "\n",
    "    for i, txt in enumerate(plot_data.label[:10]):\n",
    "        ax.annotate(txt, (xs[i] + 0.005, ys[i]))\n",
    "\n",
    "    ax.set_xlabel(\"Abs % Error of ATE\")\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_title(\"Learner Performance (averaged over k={} simulations)\".format(k))\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.1, 0.5))\n",
    "    plt.savefig(savepath)\n",
    "\n",
    "def bar_plot_summary_holdout(\n",
    "    train_summary, validation_summary, k, savepath, drop_learners=[], drop_cols=[]\n",
    "):\n",
    "    \"\"\"Generates a bar plot comparing learner performance by training and validation\n",
    "    Args:\n",
    "        train_summary (pd.DataFrame): summary for training synthetic data generated by get_synthetic_summary_holdout()\n",
    "        validation_summary (pd.DataFrame): summary for validation synthetic data generated by\n",
    "            get_synthetic_summary_holdout()\n",
    "        k (int): number of simulations (used only for plot title text)\n",
    "        drop_learners (list, optional): list of learners (str) to omit when plotting\n",
    "        drop_cols (list, optional): list of metrics (str) to omit when plotting\n",
    "    \"\"\"\n",
    "    train_summary = train_summary.drop([KEY_ACTUAL])\n",
    "    train_summary[\"Learner\"] = train_summary.index\n",
    "\n",
    "    validation_summary = validation_summary.drop([KEY_ACTUAL])\n",
    "    validation_summary[\"Learner\"] = validation_summary.index\n",
    "\n",
    "    for metric in [\"Abs % Error of ATE\", \"MSE\", \"KL Divergence\"]:\n",
    "        plot_data_sub = pd.DataFrame(train_summary.Learner).reset_index(drop=True)\n",
    "        plot_data_sub[\"train\"] = train_summary[metric].values\n",
    "        plot_data_sub[\"validation\"] = validation_summary[metric].values\n",
    "        plot_data_sub = plot_data_sub.set_index(\"Learner\")\n",
    "        plot_data_sub = plot_data_sub.drop(drop_learners).drop(drop_cols, axis=1)\n",
    "        plot_data_sub = plot_data_sub.sort_values(\"train\", ascending=True)\n",
    "\n",
    "        plot_data_sub.plot(kind=\"bar\", color=[\"red\", \"blue\"], figsize=(12, 8))\n",
    "        plt.xticks(rotation=30)\n",
    "        plt.title(\n",
    "            \"Learner Performance of {} (averaged over k={} simulations)\".format(\n",
    "                metric, k\n",
    "            )\n",
    "        )\n",
    "        plt.savefig(savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_pkls['n:200, p:5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
